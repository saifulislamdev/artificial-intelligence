{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/saifulislamdev/artificial-intelligence/blob/main/judging_flowers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "id": "S8PKiVJaL_AW"
   },
   "outputs": [],
   "source": [
    "# Imports and pip installations (if needed)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import io\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample datapoints used for classifiers throughout the code \n",
    "# In this case, just one sample datapoint\n",
    "# This datapoint is similar to row 4 (0-based index) of the Iris dataset\n",
    "\n",
    "sample_datapoints = [[5.0, 3.5, 1.5, 0.2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A05Q5B0_NUX9"
   },
   "source": [
    "# Part 1: Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "id": "YZ4MUsbXNZ0P"
   },
   "outputs": [],
   "source": [
    "# Load the dataset (load remotely, not locally)\n",
    "url = 'https://raw.github.com/pandas-dev/pandas/main/pandas/tests/io/data/csv/iris.csv'\n",
    "url_content = requests.get(url).content\n",
    "iris = pd.read_csv(io.StringIO(url_content.decode('utf-8')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SepalLength  SepalWidth  PetalLength  PetalWidth         Name\n",
       "0           5.1         3.5          1.4         0.2  Iris-setosa\n",
       "1           4.9         3.0          1.4         0.2  Iris-setosa\n",
       "2           4.7         3.2          1.3         0.2  Iris-setosa\n",
       "3           4.6         3.1          1.5         0.2  Iris-setosa\n",
       "4           5.0         3.6          1.4         0.2  Iris-setosa\n",
       "5           5.4         3.9          1.7         0.4  Iris-setosa\n",
       "6           4.6         3.4          1.4         0.3  Iris-setosa\n",
       "7           5.0         3.4          1.5         0.2  Iris-setosa\n",
       "8           4.4         2.9          1.4         0.2  Iris-setosa\n",
       "9           4.9         3.1          1.5         0.1  Iris-setosa\n",
       "10          5.4         3.7          1.5         0.2  Iris-setosa\n",
       "11          4.8         3.4          1.6         0.2  Iris-setosa\n",
       "12          4.8         3.0          1.4         0.1  Iris-setosa\n",
       "13          4.3         3.0          1.1         0.1  Iris-setosa\n",
       "14          5.8         4.0          1.2         0.2  Iris-setosa"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the first 15 rows of the data\n",
    "iris.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   SepalLength  150 non-null    float64\n",
      " 1   SepalWidth   150 non-null    float64\n",
      " 2   PetalLength  150 non-null    float64\n",
      " 3   PetalWidth   150 non-null    float64\n",
      " 4   Name         150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the table information (number of datapoints, etc.)\n",
    "iris.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRMtsJKBaxWu"
   },
   "source": [
    "## About the dataset\n",
    "**Explain what the data is in your own words. What are your features and labels? What is the mapping of your labels to the actual classes?**\n",
    "\n",
    "The data set consists of information about 150 samples of Iris flowers; 50 samples of Iris setosa, 50 samples of Iris virginica, and 50 samples of Iris versicolor (3 different species of Iris flowers). \n",
    "\n",
    "There are four features: sepal length, sepal width, petal length, and petal width. The labels are species of Iris flower: Iris setosa, Iris virginica, or Iris versicolor. Each label corresponds to an actual class (total of 3 classes). Hence, each label maps to one and only one class. \n",
    "\n",
    "One species is linearly separable from the other 2 and the other 2 are not linearly separable from each other. Taken from Fisher's paper, the Iris dataset is commonly used nowadays as a beginner's dataset for machine learning beginners like me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhKaIrZKNaHg"
   },
   "source": [
    "# Part 2: Split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "id": "OrgogB62NcOi"
   },
   "outputs": [],
   "source": [
    "# Take the dataset and split it into our features (X) and label (y)\n",
    "\n",
    "# features (X)\n",
    "X = iris[['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']].values \n",
    "\n",
    "# label (y)\n",
    "y = iris['Name'].values \n",
    "\n",
    "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hblF-ei9Ncia"
   },
   "source": [
    "# Part 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "id": "IhFhEN03Nf7o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=1)"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to train a LogisticRegression model on the training set\n",
    "lr=LogisticRegression(max_iter=1000, random_state=1)\n",
    "lr.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of Iris-setosa : 0.978466027961796\n",
      "Probability of Iris-versicolor : 0.021533922417967616\n",
      "Probability of Iris-virginica : 4.962023630008219e-08\n"
     ]
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "lr_probabilities = lr.predict_proba(sample_datapoints)[0]\n",
    "for i in range(len(lr_probabilities)):\n",
    "    print('Probability of', lr.classes_[i], ':', lr_probabilities[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iii. Report on the score for Logistic regression model, what does the score measure?\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score above represents the mean accuracy on the given test data and labels. It measures how well the model can predict the outputs of the inputs, given the inputs and expected outputs. Since I used the test data, it shows that the model accurately predicts the test labels as it returns the highest possible score (1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [[-0.44134475  0.85285733 -2.45739786 -1.00501208]\n",
      " [ 0.55059128 -0.31499028 -0.17440822 -0.93050419]\n",
      " [-0.10924652 -0.53786705  2.63180607  1.93551628]]\n",
      "Intercepts: [  9.97997382   1.85201766 -11.83199148]\n"
     ]
    }
   ],
   "source": [
    "# iv. Extract the coefficents and intercepts for the boundary line(s)\n",
    "print('Coefficients:', lr.coef_)\n",
    "print('Intercepts:', lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDUpXQN4Nilk"
   },
   "source": [
    "# Part 4: Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "id": "U__zukpdNqiQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', probability=True, random_state=1)"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to train a Support Vector Classifier on the training set\n",
    "svm=SVC(kernel='linear', probability = True, max_iter=-1, random_state=1)\n",
    "svm.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of Iris-setosa : 0.9673247206872928\n",
      "Probability of Iris-versicolor : 0.02189335691315819\n",
      "Probability of Iris-virginica : 0.010781922399549079\n"
     ]
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "svm_probabilities = svm.predict_proba(sample_datapoints)[0]\n",
    "for i in range(len(svm_probabilities)):\n",
    "    print('Probability of', svm.classes_[i], ':', svm_probabilities[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iii. Report on the score for the SVM, what does the score measure?\n",
    "svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score above represents the mean accuracy on the given test data and labels. It measures how well the model can predict the outputs of the inputs, given the inputs and expected outputs. Since I used the test data, it shows that the model accurately predicts the test labels as it returns the highest possible score (1.0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULoL7mMBNrlS"
   },
   "source": [
    "# Part 5: Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "id": "CKKmODVrN9lQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', max_iter=1000, random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to train a Neural Network (MLP Classifier) on the training set\n",
    "mlp = MLPClassifier(activation='logistic', solver='lbfgs', max_iter=1000, random_state=1)\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of Iris-setosa : 0.9999913086802718\n",
      "Probability of Iris-versicolor : 8.691319728170479e-06\n",
      "Probability of Iris-virginica : 1.2059261335854125e-33\n"
     ]
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "mlp_probabilities = mlp.predict_proba(sample_datapoints)[0]\n",
    "for i in range(len(mlp_probabilities)):\n",
    "    print('Probability of', mlp.classes_[i], ':', mlp_probabilities[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iii. Report on the score for the Neural Network, what does the score measure?\n",
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score above represents the mean accuracy on the given test data and labels. It measures how well the model can predict the outputs of the inputs, given the inputs and expected outputs. Since I used the test data, it shows that the model accurately predicts the test labels as it returns the highest possible score (1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst config: {'activation': 'relu', 'score': 1.0, 'solver': 'adam'}\n",
      "Best config: {'activation': 'relu', 'score': 1.0, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# iv: Experiment with different options for the neural network, report on your best configuration (the highest score I was able to achieve was 0.8666)\n",
    "worst_config = { \n",
    "    'score': float('inf'), # lowest score\n",
    "}\n",
    "best_config = {\n",
    "    'score': float('-inf'), # highest score\n",
    "}\n",
    "\n",
    "# Different options/configurations\n",
    "configs = [\n",
    "    {\n",
    "        'activation': 'relu', \n",
    "        'solver': 'adam', \n",
    "    },\n",
    "    {\n",
    "        'activation': 'logistic', \n",
    "        'solver': 'adam', \n",
    "    }, \n",
    "    {\n",
    "        'activation': 'relu', \n",
    "        'solver': 'lbfgs', \n",
    "    },\n",
    "    {\n",
    "        'activation': 'logistic', \n",
    "        'solver': 'lbfgs', \n",
    "    }\n",
    "]\n",
    "\n",
    "# Experiment with different options/configurations\n",
    "for config in configs:\n",
    "    curr_activation = config['activation']\n",
    "    curr_solver = config['solver']\n",
    "    curr_mlp = MLPClassifier(activation=curr_activation, solver=curr_solver, max_iter=1000, shuffle=True, random_state = 1)\n",
    "    curr_mlp.fit(X_train, y_train)\n",
    "    curr_mlp_score = curr_mlp.score(X_test, y_test)\n",
    "    if curr_mlp_score < worst_config['score']:\n",
    "        worst_config = {\n",
    "            'activation': curr_activation,\n",
    "            'score': curr_mlp_score,\n",
    "            'solver': curr_solver\n",
    "        }\n",
    "    if curr_mlp_score > best_config['score']:\n",
    "        best_config = {\n",
    "            'activation': curr_activation,\n",
    "            'score': curr_mlp_score,\n",
    "            'solver': curr_solver\n",
    "        }\n",
    "\n",
    "print('Worst config:', worst_config)\n",
    "print('Best config:', best_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best config: \n",
    "* Activation = 'relu'\n",
    "* Score = 1.0\n",
    "* Solver = 'adam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bi5tDwHmC28"
   },
   "source": [
    "# Part 6: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "id": "qCFlfJy2mCg6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to 'train' a k-Neighbors Classifier\n",
    "# Note: KNN is a nonparametric model and technically doesn't require training\n",
    "# fit will essentially load the data into the model see link below for more information\n",
    "# https://stats.stackexchange.com/questions/349842/why-do-we-need-to-fit-a-k-nearest-neighbors-classifier\n",
    "\n",
    "neigh = KNeighborsClassifier()\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of Iris-setosa : 1.0\n",
      "Probability of Iris-versicolor : 0.0\n",
      "Probability of Iris-virginica : 0.0\n"
     ]
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "neigh_probabilities = neigh.predict_proba(sample_datapoints)[0]\n",
    "for i in range(len(neigh_probabilities)):\n",
    "    print('Probability of', neigh.classes_[i], ':', neigh_probabilities[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iii. Report on the score for kNN, what does the score measure?\n",
    "neigh.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score above represents the mean accuracy on the given test data and labels. It measures how well the model can predict the outputs of the inputs, given the inputs and expected outputs. Since I used the test data, it shows that the model accurately predicts the test labels as it returns the highest possible score (1.0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "162Sw3LeoqE2"
   },
   "source": [
    "# Part 7: Conclusions and takeaways\n",
    "\n",
    "**In your own words describe the results of the notebook. Which model(s) performed the best on the dataset? Why do you think that is? Did anything surprise you about the exercise?**\n",
    "\n",
    "All the models gave a perfect score on the test set, which means that each model predicted the test labels accurately. Instead, the metric I will use is the probabilities of each possible class for each classifier. K-Neighbors Classifier returned the highest probability for Iris-setosa (1.0) among the classifiers for the same sample datapoint. The MPL Classifier (Neural Network) was super close though in having the highest probability for Iris-setosa (it was 0.99999 for MPL). \n",
    "\n",
    "It is no surprise that kNN and MPL (Neural Network) classifiers performed best on the dataset. After all, they are nonlinear classifiers and the dataset is nonlinear.\n",
    "\n",
    "At first, I found the certain probability for Iris-setosa from kNN surprising. However, looking into it further, I realized that it's not surprising when you realize what kNN really is (looking at neighbors) so it makes sense why the probability is certain. Also, I was surprised at how simple working with classification models is when utilizing machine learning libraries in Python, specifically `sklearn`."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
