{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGN9QfDXy-YX"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saifulislamdev/artificial-intelligence/blob/main/equation_of_a_slime.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {
        "id": "Cub5CQx8y-Yf"
      },
      "outputs": [],
      "source": [
        "# Imports section\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import svm\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "import io\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY1TzK0jy-Yi"
      },
      "source": [
        "## Part 1. Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "id": "PFIJUrs3y-Yi"
      },
      "outputs": [],
      "source": [
        "# Using pandas load the dataset (load remotely, not locally)\n",
        "url = \"https://raw.githubusercontent.com/profmcnich/example_notebook/main/science_data_large.csv\"\n",
        "url_content = requests.get(url).content\n",
        "df = pd.read_csv(io.StringIO(url_content.decode('utf-8')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Temperature °C  Mols KCL     Size nm^3\n",
            "0              469       647  6.244743e+05\n",
            "1              403       694  5.779610e+05\n",
            "2              302       975  6.196847e+05\n",
            "3              779       916  1.460449e+06\n",
            "4              901        18  4.325726e+04\n",
            "5              545       637  7.124634e+05\n",
            "6              660       519  7.006960e+05\n",
            "7              143       869  2.718260e+05\n",
            "8               89       461  8.919803e+04\n",
            "9              294       776  4.770210e+05\n",
            "10             991       117  2.441771e+05\n",
            "11             307       781  5.006455e+05\n",
            "12             206        70  3.145200e+04\n",
            "13             437       599  5.390215e+05\n",
            "14             566        75  9.185271e+04 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Output the first 15 rows of the data\n",
        "print(df.head(15), '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   Temperature °C  1000 non-null   int64  \n",
            " 1   Mols KCL        1000 non-null   int64  \n",
            " 2   Size nm^3       1000 non-null   float64\n",
            "dtypes: float64(1), int64(2)\n",
            "memory usage: 23.6 KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Display a summary of the table information (number of datapoints, etc.)\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT4-cEXGy-Yj"
      },
      "source": [
        "## Part 2. Splitting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "id": "7taL5uqly-Yj"
      },
      "outputs": [],
      "source": [
        "# Take the pandas dataset and split it into our features (X) and label (y)\n",
        "X = df[['Temperature °C', 'Mols KCL']].values # features (X)\n",
        "y = df['Size nm^3'].values # label (y)\n",
        "\n",
        "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
        "# random state is used to keep coefficients and intercepts consistent across reruns\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UObJqbNdy-Yk"
      },
      "source": [
        "## Part 3. Perform a Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "id": "y8EfazU2y-Yl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample datapoint output: 141562.21554556227\n",
            "Score: 0.8608840241280852\n"
          ]
        }
      ],
      "source": [
        "# Use sklearn to train a model on the training set\n",
        "reg = LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "# Create a sample datapoint and predict the output of that sample with the trained model\n",
        "sample_datapoint = [[89, 461]]\n",
        "print(\"Sample datapoint output:\", reg.predict(sample_datapoint)[0])\n",
        "\n",
        "# Report on the score for that model, in your own words (markdown, not code) explain what the score means\n",
        "print(\"Score:\", reg.score(X_train, y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The score is essentially the coefficient of determination of the prediction. It measures how well the model can predict the output of the inputs, given the expected outputs. The best possible score is 1.0. Hence, this score is not perfect, but it is okay, depending on your definition of okay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coefficients: [ 861.67891651 1036.69847878]\n",
            "Intercept: -413045.2067400077\n"
          ]
        }
      ],
      "source": [
        "# Extract the coefficents and intercept from the model and write an equation for your h(x) using LaTeX\n",
        "print(\"Coefficients:\", reg.coef_)\n",
        "print(\"Intercept:\", reg.intercept_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnlr-WBDy-Ym"
      },
      "source": [
        "$h(x) = -413045.20674 + 861.67892x_1 + 1036.69848x_2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPLDVic-y-Yo"
      },
      "source": [
        "## Part 4. Use Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "id": "4wXOSDhcy-Yp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.8744549 , 0.86605835, 0.83270803, 0.86666097, 0.84651432,\n",
              "       0.85759979, 0.83017233, 0.84737449, 0.86513442, 0.76675157,\n",
              "       0.85713635, 0.85830875, 0.87327884, 0.86868118, 0.85829925,\n",
              "       0.84173315, 0.88884666, 0.86097308, 0.83668964, 0.88030161,\n",
              "       0.85636607, 0.87230811, 0.84885618, 0.88827511, 0.86956894,\n",
              "       0.84093495, 0.8710812 , 0.86711555, 0.84878514, 0.88316784,\n",
              "       0.88535583, 0.85284702, 0.87802948, 0.84533243, 0.84716785,\n",
              "       0.86069718, 0.84407959, 0.84008055, 0.83574209, 0.85909357,\n",
              "       0.85707895, 0.83251992, 0.8369089 , 0.86778104, 0.81400614,\n",
              "       0.88458404, 0.88151102, 0.84037551, 0.79916302, 0.86615135,\n",
              "       0.87401657, 0.85757245, 0.87385828, 0.87446182, 0.86359295,\n",
              "       0.81150386, 0.85316269, 0.86733136, 0.88007221, 0.85370635,\n",
              "       0.84962353, 0.85789815, 0.85318883, 0.83597441, 0.85231969,\n",
              "       0.86606607, 0.83875678, 0.85175107, 0.87868122, 0.84157886,\n",
              "       0.82573742, 0.86537851, 0.8751695 , 0.85789074, 0.83677686,\n",
              "       0.88664888, 0.86037985, 0.86219397, 0.8354333 , 0.84984238,\n",
              "       0.87897495, 0.86030004, 0.84250366, 0.85892403, 0.86390285,\n",
              "       0.85739486, 0.8613669 , 0.8817532 , 0.8363557 , 0.84849004,\n",
              "       0.84610522, 0.85588199, 0.88403958, 0.85944042, 0.85556168,\n",
              "       0.87482751, 0.85959995, 0.84720256, 0.85331108, 0.86147262])"
            ]
          },
          "execution_count": 292,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use the cross_val_score function to repeat your experiment across many shuffles of the data\n",
        "cv = ShuffleSplit(n_splits=100, test_size=0.1, random_state=0)\n",
        "clf = svm.SVR(kernel='linear', C=1)\n",
        "scores = cross_val_score(clf, X, y, cv=cv)\n",
        "\n",
        "# Report on their finding and their significance\n",
        "scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On some shuffles of the data, the score was higher or almost the same compared to the previous score in Part 3. However, on other shuffles of the data, the score was lower, if not significantly lower (~0.10), compared to the previous score in Part 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zANZbJLiy-Yp"
      },
      "source": [
        "## Part 5. Using Polynomial Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {
        "id": "_ggi7HVhy-Yq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score: 1.0\n",
            "Coefficients: [ 0.00000000e+00  1.20000000e+01 -1.12640975e-07 -1.78967952e-11\n",
            "  2.00000000e+00  2.85714287e-02]\n",
            "Intercept: 1.470447750762105e-05\n"
          ]
        }
      ],
      "source": [
        "# Using the PolynomialFeatures library perform another regression on an augmented dataset of degree 2\n",
        "poly = PolynomialFeatures(2).fit(X_train, y_train)\n",
        "X_aug = poly.fit_transform(X)\n",
        "X_train_aug, X_test_aug, y_train_aug, y_test_aug = train_test_split(X_aug, y, test_size=0.1, random_state=1)\n",
        "poly_reg = LinearRegression().fit(X_train_aug, y_train_aug)\n",
        "\n",
        "# Report on the metrics and output the resultant equation as you did in Part 3.\n",
        "\n",
        "# Report on the score for that model, in your own words (markdown, not code) explain what the score means\n",
        "# explanation of the score is provided in the next markdown cell\n",
        "print(\"Score:\", poly_reg.score(X_train_aug, y_train_aug))\n",
        "\n",
        "# Extract the coefficents and intercept from the model and write an equation for your h(x) using LaTeX\n",
        "print(\"Coefficients:\", poly_reg.coef_)\n",
        "print(\"Intercept:\", poly_reg.intercept_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wow, this time the score was perfect! The best possible score is 1.0, and it was matched! Hence, the model predicted the output of the training set pretty well.\n",
        "\n",
        "$h(x) = 12x_1 -1.12640975*10^-7 *x_2 + -1.78967952*10^-11 *x_1^2 + 2x_1x_2 + 2.85714287*10^-2 *x_2^2$"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "a3_sample_notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
